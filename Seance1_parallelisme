etude des processeurs many cores matériellement et logiciellement

support TME :   
    soclib
    tsar
    giet
    almos mkh (os made by lip6 spécialisé manycore)

Archi manycore :

    Manycore : environ plus de 50 cores

    deux grandes catégories
        - Application specific MPSoC (Multi Proc Sys On Chip)
        - Generic MPSoC

    AS-MPSOC 
        - spécialisé pour une classe d'applications
        - co dev matériel et logiciel
        très ciblé. Ptototypé virtuellement avec du SystemC avec abstraction TLM (Transaction Level Modeling)
        sadge : coute très cher a dev et peu reutilisable. Plus c'est grand, pire c'est. Marchés de niche
                            BREF : ON S'EN BRANLE, CA PUE

    Generic MPSOC 
        - distingue clairement HW et SW
        - plus homogène et régulier et donc reutilisable / evoluable
        - polyvalent

Types de // : 

    // d'instr (ILP Instr level //) = exec de plrs instr en // d'un prog séquentiel
        - // automatique par le métériel à la volée
        - // par le programmeur ou le compil pour les algo spécifiques (signal, images...)
        bcp utilisé par intel, exec superscalaire, dans le désordre (renommage de registres éliminant les dep) si besoin, spéculative (exec // de séquences d'instr par ex de if then else) avec prédiction de branchement (hypthèses sur les conditions et sauts)

    Le // des taches = exec concurrente de programmes pouvant (ou pas) communiquer sur le meme MPSOC et la meme memoire (ou pas)
        - // auto guidée par programmeur (OpenMP, language capable d'indiquer des portions de code executables en // avec de pragma)
        - Re ecriture des prog (pthread)

    pipeline logiciel :
        // gros grain, async
        décomposition en taches succesives, ordre de traitement important, taches de durées inégale

Limite du // & loi Amdahl : 

    Constat : les innovations imposent une augmentation de la conso pour des gains de perf de moins en moins intéressants. Au dela de 100W/cm³ impossible de d'air cool. ON peut pas pousser un single core a l'infini, début des cores plus simples mais plus nombreux. La perf doit venir du // mais ca renvoie le soucis d'augmentation des perf au dev

    La // en rêve : si on // en 4 on va 4x plus vite, en vrai c'est pas le cas, car certaines parties doivent rester séquentielles :
        speedup (n) = durée (1)  / durée (n) ou n = le nb de cores.
    Idealement n = speedup(n) mais en réalité on a speedup(n) << n
        speedup(n) = 1 / (1 - p(1- 1/n))      avec p = dP / (Ds + dP)
                   = (dS + dP) / (dS + (dP/n))
        si p = 0.5, speedup(infini) = 2
        Donc on resteras toujours limité par la partie séquentielle du programme

    De plus la répartition prends du temps supplémentaire (communication et synchro des taches). Il faut donc ajouter une durée dC :
        speedup(n) = (dS + dP) / (dS + (dP/n) + dC)
    On peut meme se retrouver avec une tache exec en // prenant plus de temps qu'une exec en séquentiel !




consistance mémoire : l'ordre dans lequel le programmeur fait les modifs est celui dans lequel c'est fait en mémoire

numa seulement : on peut pas se permetttre d'avoir qu'une seule mémoire (trop de demandes). Il faut donc augmenter le nombre de banc mémoires
